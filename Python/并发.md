- [GIL锁](#gil锁)
  - [有了GIL锁就是线程安全？](#有了gil锁就是线程安全)
- [线程](#线程)
  - [线程创建](#线程创建)
  - [线程中的“锁机制”](#线程中的锁机制)
    - [死锁 \& 可重入锁](#死锁--可重入锁)
      - [死锁](#死锁)
      - [可重入锁](#可重入锁)
  - [线程池](#线程池)
- [协程](#协程)
  - [asyncio](#asyncio)
  - [gevent](#gevent)
- [yeild](#yeild)
  - [yield from](#yield-from)
- [并发安全](#并发安全)
- [Thread Local](#thread-local)
  - [Java的threadlocal](#java的threadlocal)
    - [原理](#原理)
    - [使用场景](#使用场景)
  - [python 的 thread local](#python-的-thread-local)

# GIL锁

GIL锁目的：垃圾回收的引用计数法导致内存

假设有两个线程 A 和 B 同时引用一个对象 a。  
线程 A 开始引用对象 a，此时对象 a 的引用计数为 1。   
线程 B 也开始引用对象 a，此时对象 a 的引用计数应该增加为 2，但由于引用计数操作不是原子性的，因此在增加引用计数的过程中，线程 A 和线程 B 可能同时执行引用计数的增加操作。  
由于引用计数操作不是原子性的，可能会出现这样的情况：线程 A 和线程 B 同时对引用计数进行操作，但由于操作不同步，最终计数只增加了 1，使得对象 a 的引用计数仅增加为 2 而不是 3。  
这种情况下，当线程 A 结束时，会将引用计数减少 1，导致引用计数变为 1。此时如果对象 a 的内存被释放，线程 B 再次访问对象 a 时，就会出现无效的内存访问。

CPython中还有另一个机制，叫做check_interval，意思是CPython解释器会去轮询检查线程GIL的锁住情况。每隔一段时间，Python解释器就会强制当前线程去释放GIL，这样别的线程才能有执行的机会。或者当前的线程阻塞了，会切换

## 有了GIL锁就是线程安全？

肯定不是的，要看操作本身是否原子性，比如 n=n+1 不是原子操作，即使有GIL锁，线程也可能在由于非原子操作导致线程不安全

# 线程

## 线程创建

```python
'''方法创建'''
import time
from threading import Thread

# 自定义线程函数。
def target(name="Python"):
    for i in range(2):
        print("hello", name)
        time.sleep(1)

# 创建线程01，不指定参数
thread_01 = Thread(target=target)
# 启动线程01
thread_01.start()

# 创建线程02，指定参数，注意逗号
thread_02 = Thread(target=target, args=("MING",))
# 启动线程02
thread_02.start()


'''类创建'''
import time
from threading import Thread

class MyThread(Thread):
    def __init__(self, type="Python"):
        # 注意：super().__init__() 必须写
        # 且最好写在第一行
        super().__init__()
        self.type=type

    def run(self):
        for i in range(2):
            print("hello", self.type)
            time.sleep(1)

if __name__ == '__main__':
    # 创建线程01，不指定参数
    thread_01 = MyThread()
    # 创建线程02，指定参数
    thread_02 = MyThread("MING")

    thread_01.start()
    thread_02.start()

# 如上所述，创建一个线程
t=Thread(target=func)

# 启动子线程
t.start()

# 阻塞子线程，待子线程结束后，再往下执行
t.join()

# 判断线程是否在执行状态，在执行返回True，否则返回False
t.is_alive()
t.isAlive()

# 设置线程是否随主线程退出而退出，默认为False
t.daemon = True
t.daemon = False

# 设置线程名
t.name = "My-Thread"
```

## 线程中的“锁机制”

```python
import threading

lock = threading.Lock()
# 上下文管理： 等价 lock.acquire()  lock.release()
with lock: 
    # 这里写自己的代码
    pass
```

### 死锁 & 可重入锁

#### 死锁

死锁的形式有多种多样，但是本质都是相同的，都是对资源不合理竞争的结果。

死锁通常以下几种 

- 同一线程，嵌套获取同把互斥锁，造成死锁 --- 解决：可重入锁
- 多个线程，不按顺序同时获取多个锁。造成死锁 --- 解决：按照固定顺序获取

> 线程1，嵌套获取A,B两个锁，线程2，嵌套获取B,A两个锁。 由于两个线程是交替执行的，是有机会遇到线程1获取到锁A，而未获取到锁B，在同一时刻，线程2获取到锁B，而未获取到锁A。由于锁B已经被线程2获取了，所以线程1就卡在了获取锁B处，由于是嵌套锁，线程1未获取并释放B，是不能释放锁A的，这是导致线程2也获取不到锁A，也卡住了。两个线程，各执一锁，各不让步。造成死锁。

```python
import threading
from contextlib import contextmanager

# Thread-local state to stored information on locks already acquired
_local = threading.local()

@contextmanager
def acquire(*locks):
    # Sort locks by object identifier
    locks = sorted(locks, key=lambda x: id(x))

    # Make sure lock order of previously acquired locks is not violated
    acquired = getattr(_local,'acquired',[])
    if acquired and max(id(lock) for lock in acquired) >= id(locks[0]):
        raise RuntimeError('Lock Order Violation')

    # Acquire all of the locks
    acquired.extend(locks)
    _local.acquired = acquired

    try:
        for lock in locks:
            lock.acquire()
        yield
    finally:
        # Release locks in reverse order of acquisition
        for lock in reversed(locks):
            lock.release()
        del acquired[-len(locks):]

'''
表面上thread_1的先获取锁x，再获取锁y，而thread_2是先获取锁y，再获取x。 但是实际上，acquire函数，已经对x，y两个锁进行了排序。所以thread_1，hread_2都是以同一顺序来获取锁的，是不是造成死锁的。
'''
import threading
x_lock = threading.Lock()
y_lock = threading.Lock()

def thread_1():

    while True:
        with acquire(x_lock):
            with acquire(y_lock):
                print('Thread-1')

def thread_2():
    while True:
        with acquire(y_lock):
            with acquire(x_lock):
                print('Thread-2')

t1 = threading.Thread(target=thread_1)
t1.daemon = True
t1.start()

t2 = threading.Thread(target=thread_2)
t2.daemon = True
t2.start()
```

####  可重入锁

可重入锁（RLock），只在同一线程里放松对锁(通行证)的获取，意思是，只要在同一线程里，程序就当你是同一个人，这个锁就可以复用，其他的话与Lock并无区别

```python
'''使用了嵌套锁，在锁还没有释放的时候，又再一次请求锁，这就当然会造成死锁'''
import threading

def main():
    n = 0
    lock = threading.Lock()
    with lock:
        for i in range(10):
            n += 1
            with lock:
                print(n)

t1 = threading.Thread(target=main)
t1.start()

import threading

def main():
    n = 0
    # 生成可重入锁对象
    lock = threading.RLock()
    with lock:
        for i in range(10):
            n += 1
            with lock:
                print(n)

t1 = threading.Thread(target=main)
t1.start()
```

## 线程池

```python
import time
import threading
from concurrent.futures import ThreadPoolExecutor

def target():
    for i in range(5):
        print('running thread-{}:{}'.format(threading.get_ident(), i))
        time.sleep(1)

# 创建一个最大容纳数量为5的线程池
pool = ThreadPoolExecutor(5)

for i in range(10):
    # 往线程池上塞任务
    pool.submit(target)

with ThreadPoolExecutor(5) as pool:
    for i in range(100):
        pool.submit(target)
```

# 协程

- 协程和多线程的区别，主要在于两点，一是协程为单线程；二是协程由用户决定，在哪些地方交出控制权，切换到下一个任务。
- 协程的写法更加简洁清晰，把async / await 语法和 create_task 结合来用，对于中小级别的并发需求已经毫无压力。
- 写协程程序的时候，你的脑海中要有清晰的事件循环概念，知道程序在什么时候需要暂停、等待 I/O，什么时候需要一并执行到底。

> 协程与 subroutine 不同的是，协程在执行过程中可以暂停，把线程让出（yield）给其它代码去执行，然后在某个时间点再恢复执行，这种 yield 不是调用关系而是切换，线程从一个协程的 Context 切换到了另一个协程的 Context。在这种情况下，多个协程便可以在同一线程下并发执行。也就是说，协程的暂停后再恢复机制，是为了能够让出线程的使用权，而让出线程的使用权后，就可以在当前线程去执行其它协程，也就实现了多个协程共同运行。通常也会认为 subroutine 是 coroutine 的一个特例，subroutine 是在执行中不会让出 (yeild) 的 coroutine。

以 Python 中的 sleep 为例，我们让代码睡眠 5 秒钟后继续执行，我们在函数中调用 time.sleep(5) 时，当前函数停止执行了，当前线程也是停住的，不会执行其它代码。而在协程中调用 asyncio.sleep(5) 时，当前协程停止执行了，但是当前线程仍然会继续运行，去执行其它代码，5 秒钟后当前协程自动恢复执行。需要注意的是，我们在函数中调用的是 time.sleep(5)，**而在协程中调用的是 asyncio.sleep(5)，asyncio.sleep 是协程版本的** sleep 函数。如果在协程中调用 time.sleep(5)，协程停住的5秒钟中，线程同样也是停住的，必须调用协程版本的 asyncio.sleep 才能实现协程的效果。

无论是IO阻塞还是time.sleep这类非IO阻塞。**阻塞想要协程切换，就需要协程。怎样才能有协程：gevent，asyncio等，要想实现协程序切换，需要代码中有协程切换的逻辑，而不是说用了gevent和asnycio就会切换
协程能切换：**

1、传统IO操作/time.sleep + gevnet的monkey.patch,  此时monkey patch会将IO操作/sleep等阻塞打补丁替换

2、传统IO阻塞用异步调用的库asnycio.sleep + asnycio

3、自己写yield实现

## asyncio

实现协程：

（1）事件循环 (event loop)。事件循环需要实现两个功能，一是顺序执行协程代码；二是完成协程的调度，即一个协程“暂停”时，决定接下来执行哪个协程。

（2）协程上下文的切换。基本上Python 生成器的 yeild 已经能完成切换，Python3中还有特定语法await支持协程切换。

```python
import asyncio

async def do_work(task_name, duration):
    print(f"Task {task_name} started...")
    await asyncio.sleep(duration)
    print(f"Task {task_name} finished.")

async def main():
    tasks = [
        do_work("A", 3),
        do_work("B", 2),
        do_work("C", 1)
    ]
    await asyncio.gather(*tasks)

# 创建一个事件event_loop
loop = asyncio.get_event_loop()
# 将协程加入到event_loop中，并运行
loop.run_until_complete(main())

Task A started...
Task B started...
Task C started...
Task C finished.
Task B finished.
Task A finished.
```

## gevent

monkey.patch_all() 的作用是自动化地对 Python 的一些标准库进行修改，使它们变得与 gevent 协作。这包括对time.sleep的修改，使其成为非阻塞的。

```python
import time
import gevent
from gevent import monkey
import requests 
 
# 这一过程在启动时通过monkey patch完成
monkey.patch_all()
 
 
def func_a():
    print('-------A-------')
    # time.sleep(5)
    ret = requests.get("http://www.baidu.com")
    print(ret.status_code)
    print('-------A1-------')
 
 
def func_b():
    print('-------B-------')
    # time.sleep(5)
    ret = requests.get("http://www.baidu.com")
    print(ret.status_code)
    print('-------B1-------')
 
 
# gevent.joinall([gevent.spawn(fn)
g1 = gevent.spawn(func_a)  # 创建一个协程
g2 = gevent.spawn(func_b)
g1.join()  # 等待协程执行结束
g2.join()

gevent.joinall(
    [
        gevent.spawn(func_a),
        gevent.spawn(func_b)
    ]
)
```

# yeild

```python
from collections import deque
 
def sayHello(n):
    while n > 0:
        print("hello~", n)
        yield n
        n -= 1
    print('say hello')
 
def sayHi(n):
    x = 0
    while x < n:
        print('hi~', x)
        yield
        x += 1
    print("say hi")
 
# 使用yield语句，实现简单任务调度器
class TaskScheduler(object):
    def __init__(self):
        self._task_queue = deque()
 
    def new_task(self, task):
        '''
        向调度队列添加新的任务
        '''
        self._task_queue.append(task)
 
    def run(self):
        '''
        不断运行，直到队列中没有任务
        '''
        while self._task_queue:
            task = self._task_queue.popleft()
            try:
                next(task)
                self._task_queue.append(task)
            except StopIteration:
                # 生成器结束
                pass
 
sched = TaskScheduler()
sched.new_task(sayHello(2))
sched.new_task(sayHi(3))
sched.run()　

hello~ 2
hi~ 0
hello~ 1
hi~ 1
say hello
hi~ 2
say hi
```

## yield from

yield from后面加上可迭代对象，他可以把可迭代对象里的每个元素一个一个的yield出来，对比yield来说代码更加简洁

```python
# 字符串
astr='ABC'
# 列表
alist=[1,2,3]
# 字典
adict={"name":"wangbm","age":18}
# 生成器
agen=(i for i in range(4,8))

def gen(*args, **kw):
    for item in args:
        for i in item:
            yield i

def gen(*args, **kw):
    for item in args:
        yield from item

new_list=gen(astr, alist, adict, agen)
print(list(new_list))
# ['A', 'B', 'C', 1, 2, 3, 'name', 'age', 4, 5, 6, 7]
```

# 并发安全

- 共享的资源一般需要分布式锁，比如抢票剩余500张
- 进程（副本）比如只要一个RedisClient, 这时候如果加锁就不需要分布式锁，因为每个进程需要一个

下面的单例模式，不是原子操作，会不会有并发问题：

1、多线程模式下，是可能会有的，因为线程是由OS调度的，比如刚好时间片到的时候卡在有原子操作的地方，就会有并发问题

2、协程模式下，不会有，协程的切换控制权在我们手上，此时我们没有进行切换，所以一直是这个协程在运行，且因为GIL锁的原因，此时只有一个协程运行，所以不会有并发安全问题

3、当然下面因为class CacheClient被倒导入的时候就生成了RedisClient, 所以无论多线程还是协程模式下都不会有并发安全问题；**本质还是饿汉模式**

```python
# 分布式锁保证并发安全
 def get_with_lock(self):
        """
        并发安全, 减少数据库访问压力,应对缓存击穿
        """
        lock_key = f'lock_{self.cache_key}'
        for i in range(500):
            data = self.client.get_json_val(self.cache_key)
            if data is not None:
                return data
            elif self.client.acquire_lock(lock_key):
                try:
                    data = self._get_original_data()
                    if data is not None:
                        # 允许空Dict/空List; 需要保证数据更新清空缓存
                        self.client.set_json_val(
                            self.cache_key, data, ex=self.timeout
                        )
                    return data
                finally:
                    self.client.release_lock(lock_key)
            else:
                time.sleep(0.01)
        raise InternalCustomError(msg='Redis并发锁获取失败')

# 单例模式 保证一个副本只有一个
class Singleton(type):
    """(类名)单例, metaclass=Singleton"""

    def __init__(cls, *args, **kwargs):
        cls.__instance = {}
        super().__init__(*args, **kwargs)

    def __call__(cls, *args, **kwargs):
        if cls.__name__ not in cls.__instance:
            cls.__instance[cls.__name__] = super().__call__(*args, **kwargs)
        if hasattr(cls.__instance[cls.__name__], "init"):
            cls.__instance[cls.__name__].init(*args, **kwargs)
        return cls.__instance[cls.__name__]

class RedisClient(metaclass=Singleton):
    pass

class CacheClient:
    client = RedisClient()


```

# Thread Local

## Java的threadlocal

- threadlocal是共有的，类似一个字典，其key就是线程ID，value可以存的自己定，存一个map就可以很多值
- set的时候通过线程去获取每个线程的ThreadLocalMap对象，没有的话就用线程id创建一个，这样就可以保证每个线程有一个ThreadLocalMap属性，是各自独立的属性
- threadlocal是共有变量，但每个ThreadLocalMap是线程独有的（线程隔离），是每个线程拥有的独立属性，其存在：ThreadLocal = {线程1：线程1的ThreadLocalMap，线程2：线程2的ThreadLocalMap}
- threadlocal是线程共有的，用来给每个线程设置threadlocalmap

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202402051132224.png)

### 原理

```java
public void set(T value) {  #ThreadLocal类中的
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}

// 下面是一个利用Thread对象作为句柄获取ThreadLocalMap对象的代码
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;  #返回的是该线程的变量
}

// 上面的代码获取的实际上是Thread对象的threadLocals变量，可参考下面代码
class Thread implements Runnable {
    /* ThreadLocal values pertaining to this thread. This map is maintained
     * by the ThreadLocal class. */

    ThreadLocal.ThreadLocalMap threadLocals = null;     // 这是一个线程的实例属性，每个线程私有
}


void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
```

```java
public class ThreadLocalTest {
    
    //threadlocal本身是线程公有的，用这个来给每个线程设置（thread，变量）
    //其本质设置的还是每个thread中的threadLocals属性这个ThreadLocal.ThreadLocalMap类的对象
    //需要通过ThreadLocal这个来操作每个线程中的ThreadLocalMap对象threadLocals
    private static ThreadLocal<String> threadLocal1 = new ThreadLocal<>();

    public static void main(String[] args) {
        Thread thread1 = new Thread(() -> {
            threadLocal1.set("My name is threadLocal1");
            System.out.println("thread1 name:" + threadLocal1.get());
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        Thread thread2 = new Thread(() -> {
            System.out.println("thread2 name:" + threadLocal1.get());
        });
        thread1.start();
        thread2.start();
    }
}
```

### 使用场景

**场景一：代替参数显式传递**

当我们在写API接口的时候，通常Controller层会接受来自前端的入参，当这个接口功能比较复杂的时候，可能我们调用的Service层内部还调用了 很多其他的很多方法，通常情况下，我们会在每个调用的方法上加上需要传递的参数。

但是如果我们将参数存入ThreadLocal中，那么就不用显式的传递参数了，而是只需要ThreadLocal中获取即可。

这个场景其实使用的比较少，一方面显式传参比较容易理解，另一方面我们可以将多个参数封装为对象去传递。

**场景二：全局存储用户信息**

使用ThreadLocal，我们会选择在拦截器的业务中， 获取到保存的用户信息，然后存入ThreadLocal，那么当前线程在任何地方如果需要拿到用户信息都可以使用ThreadLocal的get()方法 (异步程序中ThreadLocal是不可靠的)

**场景三：解决线程安全问题**

数据库连接：ThreadLocal缓存连接，是为了把同一个数据库连接“分享”给同一个线程的不同调用方法。（不管调用哪个方法，都是使用的同一个连接，方便进行“跨方法”的事务控制）

## python 的 thread local

- _localimpl 格式是： { id(线程1)：(ref(Thread), 线程1自身的字典), id(线程2)：(ref(Thread), 线程2自身的字典), ... }
- 和java的threadlocal原理基本一致 {线程1: 线程1的ThreadLocalMap对象，...}    
- 区别在于java的ThreadLocalMap对象是每个线程的一个属性，其通过公共的ThreadLocal去set的时候去设置这个每个线程各自的map；
- 而python的threadlocal是有个属性为_localimpl 其是一个字典，赋值的时候去操作这个公共的的threadlocal的_localimpl字典；python能这么做大概是因为其有global的原因吧

```python
import threading

#全局变量local就是一个ThreadLocal对象，每个线程对它都可以读写a属性，但互不影响。
#它本身是一个全局变量，但是每个线程却可以利用它来保存属于自己的私有数据，这些私有数据对其他线程也是不可见的。
#可以把local看成全局变量，但每个属性如local.a都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。
#threading.local() 根据每个线程id创建不同的object对象
userName = threading.local()

def SessionThread(userName_in):
    userName.val = userName_in    #userName.val，给object对象设置val属性，并赋值
    print(userName.val)   

Session1 = threading.Thread(target=SessionThread("User1"))
Session2 = threading.Thread(target=SessionThread("User2"))

# start the session threads
Session1.start()
Session2.start()
# wait till the session threads are complete
Session1.join()
Session2.join()
```