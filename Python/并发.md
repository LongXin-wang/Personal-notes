- [GIL锁](#gil锁)
  - [有了GIL锁就是线程安全？](#有了gil锁就是线程安全)
- [线程](#线程)
  - [线程创建](#线程创建)
  - [线程中的“锁机制”](#线程中的锁机制)
    - [死锁 \& 可重入锁](#死锁--可重入锁)
      - [死锁](#死锁)
      - [可重入锁](#可重入锁)
  - [线程池](#线程池)
- [并发安全](#并发安全)
- [Thread Local](#thread-local)
  - [Java的threadlocal](#java的threadlocal)
    - [原理](#原理)
    - [使用场景](#使用场景)
  - [python 的 thread local](#python-的-thread-local)
- [IO 模型](#io-模型)
  - [阻塞BIO/非阻塞NIO](#阻塞bio非阻塞nio)
  - [IO 多路复用](#io-多路复用)
    - [用户态去调用](#用户态去调用)
  - [select](#select)
  - [poll](#poll)
  - [epoll](#epoll)

# GIL锁

GIL锁目的：垃圾回收的引用计数法导致内存

假设有两个线程 A 和 B 同时引用一个对象 a。  
线程 A 开始引用对象 a，此时对象 a 的引用计数为 1。   
线程 B 也开始引用对象 a，此时对象 a 的引用计数应该增加为 2，但由于引用计数操作不是原子性的，因此在增加引用计数的过程中，线程 A 和线程 B 可能同时执行引用计数的增加操作。  
由于引用计数操作不是原子性的，可能会出现这样的情况：线程 A 和线程 B 同时对引用计数进行操作，但由于操作不同步，最终计数只增加了 1，使得对象 a 的引用计数仅增加为 2 而不是 3。  
这种情况下，当线程 A 结束时，会将引用计数减少 1，导致引用计数变为 1。此时如果对象 a 的内存被释放，线程 B 再次访问对象 a 时，就会出现无效的内存访问。

CPython中还有另一个机制，叫做check_interval，意思是CPython解释器会去轮询检查线程GIL的锁住情况。每隔一段时间，Python解释器就会强制当前线程去释放GIL，这样别的线程才能有执行的机会。或者当前的线程阻塞了，会切换

## 有了GIL锁就是线程安全？

肯定不是的，要看操作本身是否原子性，比如 n=n+1 不是原子操作，即使有GIL锁，线程也可能在由于非原子操作导致线程不安全

# 线程

## 线程创建

```python
'''方法创建'''
import time
from threading import Thread

# 自定义线程函数。
def target(name="Python"):
    for i in range(2):
        print("hello", name)
        time.sleep(1)

# 创建线程01，不指定参数
thread_01 = Thread(target=target)
# 启动线程01
thread_01.start()

# 创建线程02，指定参数，注意逗号
thread_02 = Thread(target=target, args=("MING",))
# 启动线程02
thread_02.start()


'''类创建'''
import time
from threading import Thread

class MyThread(Thread):
    def __init__(self, type="Python"):
        # 注意：super().__init__() 必须写
        # 且最好写在第一行
        super().__init__()
        self.type=type

    def run(self):
        for i in range(2):
            print("hello", self.type)
            time.sleep(1)

if __name__ == '__main__':
    # 创建线程01，不指定参数
    thread_01 = MyThread()
    # 创建线程02，指定参数
    thread_02 = MyThread("MING")

    thread_01.start()
    thread_02.start()

# 如上所述，创建一个线程
t=Thread(target=func)

# 启动子线程
t.start()

# 阻塞子线程，待子线程结束后，再往下执行
t.join()

# 判断线程是否在执行状态，在执行返回True，否则返回False
t.is_alive()
t.isAlive()

# 设置线程是否随主线程退出而退出，默认为False
t.daemon = True
t.daemon = False

# 设置线程名
t.name = "My-Thread"
```

## 线程中的“锁机制”

```python
import threading

lock = threading.Lock()
# 上下文管理： 等价 lock.acquire()  lock.release()
with lock: 
    # 这里写自己的代码
    pass
```

### 死锁 & 可重入锁

#### 死锁

死锁的形式有多种多样，但是本质都是相同的，都是对资源不合理竞争的结果。

死锁通常以下几种 

- 同一线程，嵌套获取同把互斥锁，造成死锁 --- 解决：可重入锁
- 多个线程，不按顺序同时获取多个锁。造成死锁 --- 解决：按照固定顺序获取

> 线程1，嵌套获取A,B两个锁，线程2，嵌套获取B,A两个锁。 由于两个线程是交替执行的，是有机会遇到线程1获取到锁A，而未获取到锁B，在同一时刻，线程2获取到锁B，而未获取到锁A。由于锁B已经被线程2获取了，所以线程1就卡在了获取锁B处，由于是嵌套锁，线程1未获取并释放B，是不能释放锁A的，这是导致线程2也获取不到锁A，也卡住了。两个线程，各执一锁，各不让步。造成死锁。

```python
import threading
from contextlib import contextmanager

# Thread-local state to stored information on locks already acquired
_local = threading.local()

@contextmanager
def acquire(*locks):
    # Sort locks by object identifier
    locks = sorted(locks, key=lambda x: id(x))

    # Make sure lock order of previously acquired locks is not violated
    acquired = getattr(_local,'acquired',[])
    if acquired and max(id(lock) for lock in acquired) >= id(locks[0]):
        raise RuntimeError('Lock Order Violation')

    # Acquire all of the locks
    acquired.extend(locks)
    _local.acquired = acquired

    try:
        for lock in locks:
            lock.acquire()
        yield
    finally:
        # Release locks in reverse order of acquisition
        for lock in reversed(locks):
            lock.release()
        del acquired[-len(locks):]

'''
表面上thread_1的先获取锁x，再获取锁y，而thread_2是先获取锁y，再获取x。 但是实际上，acquire函数，已经对x，y两个锁进行了排序。所以thread_1，hread_2都是以同一顺序来获取锁的，是不是造成死锁的。
'''
import threading
x_lock = threading.Lock()
y_lock = threading.Lock()

def thread_1():

    while True:
        with acquire(x_lock):
            with acquire(y_lock):
                print('Thread-1')

def thread_2():
    while True:
        with acquire(y_lock):
            with acquire(x_lock):
                print('Thread-2')

t1 = threading.Thread(target=thread_1)
t1.daemon = True
t1.start()

t2 = threading.Thread(target=thread_2)
t2.daemon = True
t2.start()
```

####  可重入锁

可重入锁（RLock），只在同一线程里放松对锁(通行证)的获取，意思是，只要在同一线程里，程序就当你是同一个人，这个锁就可以复用，其他的话与Lock并无区别

假设有一个包含两个函数的程序，其中函数A和函数B都需要获取同一个可重入锁（RLock）。如果程序中的线程T1在执行函数A时获取了这个锁，然后在函数A内部调用了函数B，而函数B也需要获取这个锁，由于可重入锁的特性，线程T1可以再次获取这个锁，而不会被自己所持有的锁所阻塞。这样可以避免死锁，同时确保同一线程内部的锁使用是安全的。

```python
'''使用了嵌套锁，在锁还没有释放的时候，又再一次请求锁，这就当然会造成死锁'''
import threading

def main():
    n = 0
    lock = threading.Lock()
    with lock:
        for i in range(10):
            n += 1
            with lock:
                print(n)

t1 = threading.Thread(target=main)
t1.start()

import threading

def main():
    n = 0
    # 生成可重入锁对象
    lock = threading.RLock()
    with lock:
        for i in range(10):
            n += 1
            with lock:
                print(n)

t1 = threading.Thread(target=main)
t1.start()
```

## 线程池

```python
import time
import threading
from concurrent.futures import ThreadPoolExecutor

def target():
    for i in range(5):
        print('running thread-{}:{}'.format(threading.get_ident(), i))
        time.sleep(1)

# 创建一个最大容纳数量为5的线程池
pool = ThreadPoolExecutor(5)

for i in range(10):
    # 往线程池上塞任务
    pool.submit(target)

with ThreadPoolExecutor(5) as pool:
    for i in range(100):
        pool.submit(target)
```

# 并发安全

- 共享的资源一般需要分布式锁，比如抢票剩余500张
- 进程（副本）比如只要一个RedisClient, 这时候如果加锁就不需要分布式锁，因为每个进程需要一个

下面的单例模式，不是原子操作，会不会有并发问题：

1、多线程模式下，是可能会有的，因为线程是由OS调度的，比如刚好时间片到的时候卡在有原子操作的地方，就会有并发问题

2、协程模式下，不会有，协程的切换控制权在我们手上，此时我们没有进行切换，所以一直是这个协程在运行，且因为GIL锁的原因，此时只有一个协程运行，所以不会有并发安全问题

3、当然下面因为class CacheClient被倒导入的时候就生成了RedisClient, 所以无论多线程还是协程模式下都不会有并发安全问题；**本质还是饿汉模式**

```python
# 分布式锁保证并发安全
 def get_with_lock(self):
        """
        并发安全, 减少数据库访问压力,应对缓存击穿
        """
        lock_key = f'lock_{self.cache_key}'
        for i in range(500):
            data = self.client.get_json_val(self.cache_key)
            if data is not None:
                return data
            elif self.client.acquire_lock(lock_key):
                try:
                    data = self._get_original_data()
                    if data is not None:
                        # 允许空Dict/空List; 需要保证数据更新清空缓存
                        self.client.set_json_val(
                            self.cache_key, data, ex=self.timeout
                        )
                    return data
                finally:
                    self.client.release_lock(lock_key)
            else:
                time.sleep(0.01)
        raise InternalCustomError(msg='Redis并发锁获取失败')

# 单例模式 保证一个副本只有一个
class Singleton(type):
    """(类名)单例, metaclass=Singleton"""

    def __init__(cls, *args, **kwargs):
        cls.__instance = {}
        super().__init__(*args, **kwargs)

    def __call__(cls, *args, **kwargs):
        if cls.__name__ not in cls.__instance:
            cls.__instance[cls.__name__] = super().__call__(*args, **kwargs)
        if hasattr(cls.__instance[cls.__name__], "init"):
            cls.__instance[cls.__name__].init(*args, **kwargs)
        return cls.__instance[cls.__name__]

class RedisClient(metaclass=Singleton):
    pass

class CacheClient:
    client = RedisClient()


```

# Thread Local

## Java的threadlocal

- threadlocal是共有的，类似一个字典，其key就是线程ID，value可以存的自己定，存一个map就可以很多值
- set的时候通过线程去获取每个线程的ThreadLocalMap对象，没有的话就用线程id创建一个，这样就可以保证每个线程有一个ThreadLocalMap属性，是各自独立的属性
- threadlocal是共有变量，但每个ThreadLocalMap是线程独有的（线程隔离），是每个线程拥有的独立属性，其存在：ThreadLocal = {线程1：线程1的ThreadLocalMap，线程2：线程2的ThreadLocalMap}
- threadlocal是线程共有的，用来给每个线程设置threadlocalmap

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202402051132224.png)

### 原理

```java
public void set(T value) {  #ThreadLocal类中的
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}

// 下面是一个利用Thread对象作为句柄获取ThreadLocalMap对象的代码
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;  #返回的是该线程的变量
}

// 上面的代码获取的实际上是Thread对象的threadLocals变量，可参考下面代码
class Thread implements Runnable {
    /* ThreadLocal values pertaining to this thread. This map is maintained
     * by the ThreadLocal class. */

    ThreadLocal.ThreadLocalMap threadLocals = null;     // 这是一个线程的实例属性，每个线程私有
}


void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}
```

```java
public class ThreadLocalTest {
    
    //threadlocal本身是线程公有的，用这个来给每个线程设置（thread，变量）
    //其本质设置的还是每个thread中的threadLocals属性这个ThreadLocal.ThreadLocalMap类的对象
    //需要通过ThreadLocal这个来操作每个线程中的ThreadLocalMap对象threadLocals
    private static ThreadLocal<String> threadLocal1 = new ThreadLocal<>();

    public static void main(String[] args) {
        Thread thread1 = new Thread(() -> {
            threadLocal1.set("My name is threadLocal1");
            System.out.println("thread1 name:" + threadLocal1.get());
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });

        Thread thread2 = new Thread(() -> {
            System.out.println("thread2 name:" + threadLocal1.get());
        });
        thread1.start();
        thread2.start();
    }
}
```

### 使用场景

**场景一：代替参数显式传递**

当我们在写API接口的时候，通常Controller层会接受来自前端的入参，当这个接口功能比较复杂的时候，可能我们调用的Service层内部还调用了 很多其他的很多方法，通常情况下，我们会在每个调用的方法上加上需要传递的参数。

但是如果我们将参数存入ThreadLocal中，那么就不用显式的传递参数了，而是只需要ThreadLocal中获取即可。

这个场景其实使用的比较少，一方面显式传参比较容易理解，另一方面我们可以将多个参数封装为对象去传递。

**场景二：全局存储用户信息**

使用ThreadLocal，我们会选择在拦截器的业务中， 获取到保存的用户信息，然后存入ThreadLocal，那么当前线程在任何地方如果需要拿到用户信息都可以使用ThreadLocal的get()方法 (异步程序中ThreadLocal是不可靠的)

**场景三：解决线程安全问题**

数据库连接：ThreadLocal缓存连接，是为了把同一个数据库连接“分享”给同一个线程的不同调用方法。（不管调用哪个方法，都是使用的同一个连接，方便进行“跨方法”的事务控制）

## python 的 thread local

- _localimpl 格式是： { id(线程1)：(ref(Thread), 线程1自身的字典), id(线程2)：(ref(Thread), 线程2自身的字典), ... }
- 和java的threadlocal原理基本一致 {线程1: 线程1的ThreadLocalMap对象，...}    
- 区别在于java的ThreadLocalMap对象是每个线程的一个属性，其通过公共的ThreadLocal去set的时候去设置这个每个线程各自的map；
- 而python的threadlocal是有个属性为_localimpl 其是一个字典，赋值的时候去操作这个公共的的threadlocal的_localimpl字典；python能这么做大概是因为其有global的原因吧

```python
import threading

#全局变量local就是一个ThreadLocal对象，每个线程对它都可以读写a属性，但互不影响。
#它本身是一个全局变量，但是每个线程却可以利用它来保存属于自己的私有数据，这些私有数据对其他线程也是不可见的。
#可以把local看成全局变量，但每个属性如local.a都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理。
#threading.local() 根据每个线程id创建不同的object对象
userName = threading.local()

def SessionThread(userName_in):
    userName.val = userName_in    #userName.val，给object对象设置val属性，并赋值
    print(userName.val)   

Session1 = threading.Thread(target=SessionThread("User1"))
Session2 = threading.Thread(target=SessionThread("User2"))

# start the session threads
Session1.start()
Session2.start()
# wait till the session threads are complete
Session1.join()
Session2.join()
```

# IO 模型

- 操作系统提供的read()函数，是阻塞IO；为了破局，程序员使用多线程去调用read，这不是非阻塞IO，而是我们做的处理；但是毕竟操作系统资源有限，线程太多影响太大
- 于是，操作系统给我们提供了一个非阻塞的read()函数，这个 read 函数的效果是，如果没有数据到达时（到达网卡并拷贝到了内核缓冲区），立刻返回一个错误值（-1），而不是阻塞地等待。非阻塞的 read，指的是在数据到达前，即数据还未到达网卡，或者到达网卡但还没有拷贝到内核缓冲区之前，这个阶段是非阻塞的。当数据已到达内核缓冲区，此时调用 read 函数仍然是阻塞的，需要等待数据从内核缓冲区拷贝到用户缓冲区，才能返回。但多个文件描述符的读取就需要遍历，当高并发场景越来越多时，用户态遍历的文件描述符也越来越多，相当于在 while 循环里进行了越来越多的系统调用。用户态遍历很消耗资源
- 为每个客户端创建一个线程，服务器端的线程资源很容易被耗光。当然还有个聪明的办法，我们可以每 accept 一个客户端连接后，将这个文件描述符（connfd）放到一个数组里。然后弄一个新的线程去不断遍历这个数组，调用每一个元素的非阻塞 read 方法。多路复用产生的效果，完全可以由用户态去遍历文件描述符并调用其非阻塞的 read 函数实现。而多路复用快的原因在于，操作系统提供了这样的系统调用，使得原来的 while 循环里多次系统调用，变成了一次系统调用 + 内核层遍历这些文件描述符。

## 阻塞BIO/非阻塞NIO

BIO （Block IO）：同步阻塞IO。一般我们传统的JDK内置的Socket编程就是阻塞IO。其底层流程是：①创建socket接口，号为x，通过bind函数将接口号与端口号进行绑定，然后进行listen事件或者是read读事件，且会一直阻塞在该命令，直到有客户端连接或者发送数据。
缺点：如果是在单线程环境下，由于是阻塞地获取结果，只能有一个客户端连接。而如果是在多线程环境下，需要不断地新建线程来接收客户端，这样会浪费大量的空间。

NIO（NONBLOCK IO）：同步非阻塞IO。非阻塞意味着程序无需等到结果，持续进行。其底层原理是：①同样与BIO相同创建Socket接口，号为x，绑定接口号与端口号，然后进行listen监听事件或者是读数据事件。②通过configureBlock函数传入参数false，底层命令为 fcntl（socket号，nonblock）将socket号标记为非阻塞。③循环执行。假如有客户端进行连接，则返回一个新的socket号，将新的socket号加入一个list中，然后遍历list中的元素查看有无发生read事件；如果没有客户端进行连接，则返回-1，代表没有客户端连接，再不断地循环。
缺点：需要遍历list中的每个集合查看有无监听的事件发生，时间复杂度为O（n），浪费CPU资源。整个IO请求的过程中，虽然用户线程每次发起IO请求后可以立即返回，但是为了等到数据，仍需要不断地轮询、重复请求，消耗了大量的CPU的资源。一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性。

## IO 多路复用

### 用户态去调用

用户态去遍历文件描述符并调用其 read 函数实现, 每次都会去调用read看起是不是-1 消耗资源

用户态非阻塞需要不断轮询，且一次轮询就查询到一个socket fd就去处理一个

IO多路复用则不需要轮询去查看socket 数据准备好没，而是只要有socket的数据准备好之后会通知（内核层遍历然后通知），借助select/poll/epoll完成

```C
fdlist.add(connfd);
# 用户态while循环多次系统调用   将fd放到list，用户态去循环调用，每次都会有read系统调用
while(1) {
  for(fd <-- fdlist) {
    if(read(fd) != -1) {
      doSomeThing(); #read
    }
  }
}


# select
while(1) {
   // 把一堆文件描述符 list 传给 select 函数
  // 有已就绪的文件描述符就返回，nready 表示有多少个就绪的
  nready = select(list);
  // 用户层依然要遍历，只不过少了很多无效的系统调用 只有效的read系统调用
  for(fd <-- fdlist) {
    if(fd != -1) {
      // 只读已就绪的文件描述符
      read(fd, buf);
      // 总共只有 nready 个已就绪描述符，不用过多遍历
      if(--nready == 0) break;
    }
  }
}
```

## select

select：需要把想监控的文件描述集合通过函数参数的形式告诉select，然后select会将这些文件描述符集合拷贝到内核中，为了减少数据拷贝带来的性能损耗，Linux内核对集合的大小做了限制，规定用户监控的文件描述集合不能超过1024个，同时当**select返回后我们仅仅能知道有些文件描述符可以读写了**，但是我们不知道是哪一个，因此程序员必须再遍历一边找到具体是哪个文件描述符可以读写了。

用户首先将需要进行IO操作的socket添加到select中，然后阻塞等待select系统调用返回。当数据到达时，socket被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行。

select 如果任何一个socket(I/O stream)出现了数据，select 仅仅会返回[0,1,0,0,0]，但不会告诉是那个socket上有数据，只能自己遍历查找。

内核态做遍历，将已经就绪的做好标识，到用户态还是需要读取list遍历

```C
while(1) {
  # 有已就绪的文件描述符就返回，nready 表示有多少个就绪的
  nready = select(list);
  // 用户层依然要遍历，只不过少了很多无效的系统调用
  for(fd <-- fdlist) {
    if(fd != -1) {
      // 只读已就绪的文件描述符
      read(fd, buf);
      // 总共只有 nready 个已就绪描述符，不用过多遍历
      if(--nready == 0) break;
    }
  }
}
```

## poll

poll是另一种I/O多路复用的实现方式，它与 select 的流程基本相似，时间复杂度是O（n），底层用链表存储fd，主要解决了 select 1024个文件描述符的限制问题，不过仍然存在文件描述符状态在用户态和内核态的频繁拷贝，和遍历所有文件描述符的问题，这导致了在面对高并发的实现需求时，它的性能不会很高。

## epoll

1. 减少了文件描述符的遍历，`select` 和 `poll` 每次都要遍历所有的文件描述符，用来判断哪个连接准备就绪；`epoll` 返回的是准备就绪的文件描述符，效率大大提高；epoll 现在不仅告诉你sock组里面数据，还会告诉你具体哪个sock有数据，你不用自己去找了。
   
2. `epoll_create()` 方法生成一个 epoll 专用的文件描述符epfd，epfd在用户态和内核态之间共享，避免了poll和select用户态和内核态文件描述符状态的拷贝。

epoll 主要就是针对这三点进行了改进。

1. 内核中保存一份文件描述符集合，无需用户每次都重新传入，只需告诉内核修改的部分即可。
2. 内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步 IO 事件唤醒。
3. 内核仅会将有 IO 事件的文件描述符返回给用户，用户也无需遍历整个文件描述符集合。

```C
// 创建 epoll 实例
int epfd = epoll_create(10);
struct epoll_event events[MAX_EVENTS];

while (1) {
    // 等待事件就绪
    int nready = epoll_wait(epfd, events, MAX_EVENTS, -1);

    // 用户 处理就绪事件
    for (int i = 0; i < nready; i++) {
        if (events[i].events & EPOLLIN) {
            // 读取就绪的文件描述符
            read(events[i].data.fd, buf, BUF_SIZE);
        }
    }
}
```