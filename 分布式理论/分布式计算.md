- [注册发现](#注册发现)
  - [中介存储](#中介存储)
  - [状态更新和通知](#状态更新和通知)
- [负载均衡](#负载均衡)
  - [无状态的负载均衡](#无状态的负载均衡)
    - [轮询](#轮询)
    - [权重轮询](#权重轮询)
  - [有状态的负载均衡](#有状态的负载均衡)
    - [Hash](#hash)
    - [一致性Hash](#一致性hash)
      - [虚拟节点](#虚拟节点)
    - [路由](#路由)
- [配置中心](#配置中心)
- [分布式锁](#分布式锁)
- [重试幂等](#重试幂等)
- [雪崩](#雪崩)
  - [熔断](#熔断)
    - [熔断的粒度控制](#熔断的粒度控制)
    - [错误类型](#错误类型)
  - [限流](#限流)
    - [限流算法](#限流算法)
      - [固定窗口和滑动窗口](#固定窗口和滑动窗口)
      - [漏桶和令牌桶](#漏桶和令牌桶)
    - [单节点限流](#单节点限流)
    - [分布式限流](#分布式限流)
  - [降级](#降级)
  - [扩容](#扩容)


# 注册发现

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202401302012241.png)

首先，最容易想到的方式是配置 IP 和 Port 列表，即直接在服务 A 的配置文件中配置服务 B 的 IP 和 Port，如果服务 B 有多个实例，那么就配置一个列表。

这样的确解决了问题，但是如果服务 C、D、E 等非常多的服务，都需要调用服务 B，那么这些服务都需要维护服务 B 的 IP 和 Port 列表。每一次当服务 B 增加、删除一个实例，或者一个实例的 IP 和 Port 发生改变时，所有调用服务 B 的服务都需要更新配置，这是一个非常繁杂并且容易出错的工作，那么怎么避免这个问题呢？

其实，我们可以将配置 IP 和 Port 列表的方式修改为配置域名和 Port，即在服务 A 的配置文件中不再配置服务 B 的 IP 和 Port 列表，而是配置服务 B 的域名和 Port。这样可以通过域名解析获得所有服务 B 的 IP 列表，让所有的服务 B 都监听同一个 Port。

当服务 B 的实例有变更，不论有多少个服务调用服务 B，只需要修改服务 B 的域名解析就行了，这样就解决了配置分散到各个调用服务，导致配置一致性的问题。

所以，经过前面的讨论，我们可以得出服务注册发现需要解决的两个关键问题：

统一的中介存储：调用方在唯一的地方获得被调用服务的所有实例的信息。
状态更新与通知：服务实例的信息能够及时更新并且通知到服务调用方。

## 中介存储

所以更合适的存储系统为 etcd、ZooKeeper 和Eureka。如果你希望在系统出现网络分区的时候，调用方一定不能获取过期的被调用服务实例信息，那么就选择 etcd 和 ZooKeeper，但是在被分区的部分网络中，可能出现因为不能获取被调用服务实例信息，而导致请求失败的情况。如果你认为获取过期的实例信息，可能比完全不能获取被调用服务的实例信息要好，那么就选择 Eureka。

## 状态更新和通知

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202401311021743.png)

首先是服务的状态更新，即服务注册：如上图中的 1，服务的每一个实例每隔一段时间，比如 30 秒，主动向中介存储上报一次自己的 IP 和 Port 信息，同时告诉中介存储这一信息的有效期，比如 90 秒。这样如果实例一直存活，那么每隔 30 秒，它都会将自己的状态信息更新到中介存储。如果实例崩溃或者被 Kill 了，那么 90 秒后，中介存储就会自动将该实例的信息清除，避免了实例信息的不一致。所以这里的数据同步是最终一致性的。

然后是服务的状态通知，即服务发现：如上图中的 2，服务的调用方通过中介存储监听被调用服务的状态变更信息。这里可以采用“发布/订阅”模式，也可以采用轮询模式，比如每30秒去中介存储获取一次。所以这里的数据同步也是最终一致性的。

# 负载均衡

**公平性 正确性**

## 无状态的负载均衡

参与负载均衡的后端实例是无状态的，所有的后端实例都是对等的，一个请求不论发向哪一个实例，都会得到相同的并且正确的处理结果，所以无状态的负载均衡策略不需要关心请求的状态。

### 轮询

轮询的负载均衡策略非常简单，只需要将请求按顺序分配给多个实例，不用再做其他的处理。例如，轮询策略会将第一个请求分配给第一个实例，然后将下一个请求分配给第二个实例，这样依次分配下去，分配完一轮之后，再回到开头分配给第一个实例，再依次分配。

### 权重轮询

权重轮询的负载均衡策略是将每一个后端实例分配一个权重，分配请求的数量和实例的权重成正比轮询。例如有两个实例 A，B，假设我们设置 A 的权重为 20，B 的权重为 80，那么负载均衡会将 20% 的请求数量分配给 A，80 % 的请求数量分配给 B。

## 有状态的负载均衡

**按照策略进行路由**

### Hash

哈希算法虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。

### 一致性Hash

Hash 的负载均衡策略中，最大的一个问题是基于机器数量求模，如果机器数量发生变化，请求和实例的分配关系机会将全部变化，这会影响它的正确性，而一致性 Hash 就可以用来解决这个问题

在一致性哈希算法中，当节点数量发生变化时，通常不需要进行传统意义上的"rehash"。一致性哈希算法的设计使得在节点的增加或减少时，只有少量的数据需要重新映射到新的节点上。这意味着大部分数据仍然会被映射到原来的节点上，因此无需进行全局性的数据迁移。这是一致性哈希算法相对于传统哈希算法的优势之一。

- 一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值。
- 根据key算出的hash值始终在环的固定位置，节点增减影响key到哪个节点
- 和hash不一样在于，hash其1-5不会分布在一个节点（因为分母是机器数量），但是一致性hash1-5可能在一个节点（分母是2^ 32），说白了，一致性hash更像是一段数据在一个节点
- 一致性hash不需要大量数据迁移，就近数据迁移（当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上）
- 节点分布不均

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202401311611659.png)

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202401311612562.png)

#### 虚拟节点

**解决节点分布不均问题**

- 每个节点对应很多虚拟节点，需要数量足够多，且每个虚拟节点周围的虚拟节点要均匀分布不同的虚拟节点，比如A1下一个是B1，A2下一个时C1，A3下一个时D1
- 减少一个节点时，其虚拟节点的数据被均匀迁移到其它节点
- 增加一个节点时，周围其他虚拟节点的数据被部分均匀迁移到该节点

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202401311638829.png)

### 路由

严格规定

# 配置中心

# 分布式锁

# 重试幂等

# 雪崩

局部故障被正反馈循环，从而导致的不断放大的连锁故障

服务的处理能力出现过载，超过QPS，资源耗尽

## 熔断

熔断机制。当服务之间发起调用的时候，如果被调用方返回的指定错误码的比例超过一定的阈值，那么后续的请求将不会真正发起，而是由调用方直接返回错误。

- 闭合状态下，请求失败，但是未达到失败阈值
- 请求失败，达到失败阈值，进入断开状态，此时，熔断，调用方直接返回错误
- 闭合状态下，会启动一个超时计时器，当计时器超时后，状态切换到半打开状态。在该状态下，允许应用程序将一定数量的请求发往被调用服务，如果这些调用正常，那么就可以认为被调用服务已经恢复正常，此时熔断器切换到闭合状态

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202402011012521.png)

### 熔断的粒度控制

服务、实例很不好，接口还可以

**实例的接口** 

### 错误类型

由于熔断机制是用来消除系统过载的，所以，我们需要识别出与系统过载相关的错误，来进行熔断处理，一般来说，主要有下面两个错误类型。

第一，系统被动对外表现出来的过载错误，一般来说，如果一个接口过载了，那么它的响应时间就会变长，熔断器捕获到的错误类型就是“响应超时”之类的超时错误。

第二，系统主动对外表现出来的过载错误，对于这种情况，一般是请求的流量触发了限流等机制返回的错误码，这个是我们在程序开发过程中主动设计的。

另外，我们要记住，熔断机制一定不要关心应用层的错误，比如余额不足之类的错误，因为这一类型的错误和系统的过载没有关系。

## 限流

### 限流算法

#### 固定窗口和滑动窗口

固定窗口

2s限制100次

- 前10ms就达到100次
- 该周期最后10ms达到100次，下一个周期前10ms又达到100次

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202402011041212.png)

滑动窗口

解决相邻周期请求集中的问题：该周期最后10ms达到100次，下一个周期前10ms又达到100次

同样的，前10ms就达到100次，这个问题（抖动问题，突然拔高）依旧存在

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202402011044700.png)

#### 漏桶和令牌桶

漏桶

相对于滑动窗口和固定窗口来说，漏桶有两个改进点，第一，增加了一个桶来缓存请求，在流量突增的时候，可以先缓存起来，直到超过桶的容量才触发限流；第二，对出口的流量上限做了限制，使上游流量的抖动不会扩散到下游服务

漏桶提供流量整形能力有一定的代价，超过漏桶流出速率的请求，需要先在漏桶中排队等待，其中流出速率是漏桶限流的防线，一般会设置得相对保守，可是这样就无法完全利用系统的性能，就增加了请求的排队时间，说白了就是突发流量的处理变慢

固定速率处理请求

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202402011130465.png)

令牌桶

令牌桶以“恒定”的速率生产令牌，但是请求获取令牌的速率是“可变”的，可处理突发流量，但是也就会有抖动

![](https://gitee.com/wanglongxin666/pictures/raw/master/img/202402011131183.png)

### 单节点限流

就是按照服务实例来，比如python装饰器在某些接口上

触发限流后：阻塞式限流还是否决式（直接抛弃请求）限流

### 分布式限流

集中限流，比如在 网关层

限流总阈值按照比例分配给服务实例

## 降级

虽然熔断机制可以确保系统不会雪崩，限流可以确保，被保护的服务不会因为过载而出现故障，可是这时候，系统的可用性或多或少都会受到一定的影响，并且这个影响不会区分核心业务和非核心业务。

那么你的脑海里一定会出现一个想法，是否可以在故障出现的时候，通过减少或停掉非核心业务，来降低系统的负载，让核心业务不会受到，或者少受到影响呢？其实是可以的，这就是一个典型的降级场景问题。

在当前极客时间的后端系统出现了过载问题的时候，或者我们预计到由于运营活动会出现突发流量的时候，我们有账号、支付和评论三个服务，停掉任意一个服务都可以让系统正常运行，那么相对于账号和支付这两个非常核心的服务，毫无疑问，我们会选择停掉评论服务来丢车保帅，降低系统故障对外的影响，这其实就是降级的核心思路。

首先，因为熔断机制是系统稳定性保障的最后一道防线，并且它是自适应的，所以我们应该在系统全局默认启用；其次，限流是用来保障被限流服务稳定性的，所以我们建议，一般在系统的核心链路和核心服务上，默认启用限流机制；最后，降级是通过牺牲被降级的接口或者服务，来保障其他的接口和服务正常运行的，所以我们可以通过降级直接停用非核心服务，然后对于核心接口和服务，在必要的时候，可以提供一个“ B 计划”。


## 扩容

加机器

首先，对于容器层面的扩容有两个维度，一个是水平扩容，即通过增加服务的实例数量对系统进行扩容；另一个是垂直扩容，即通过升级服务部署节点的资源对系统进行扩容。




